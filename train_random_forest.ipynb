{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   joblib import dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from   sklearn.ensemble import RandomForestClassifier\n",
    "from   sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from   source.feature_importance import extract_feature_importance, plot_feature_importance, rank_feature_importance\n",
    "from   source.feature_selection import remove_correlated_features\n",
    "from   source.model_evaluation import adjusted_prediction, eval_sensitivity_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature files (contains patient info and pyradiomics features)\n",
    "feature_file_training_set = 'data/training_features.csv' # RVC dataset\n",
    "label_file_training_set   = 'data/training_labels.csv'\n",
    "\n",
    "# Number of thresholds\n",
    "n_thresholds = 401\n",
    "\n",
    "# Feature selection\n",
    "corr_threshold    = 0.8\n",
    "\n",
    "# Fix seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pyradiomics features and labels\n",
    "df_features_training = pd.read_csv(feature_file_training_set)\n",
    "labels_training      = np.loadtxt(label_file_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "      <th>feature 6</th>\n",
       "      <th>feature 7</th>\n",
       "      <th>feature 8</th>\n",
       "      <th>feature 9</th>\n",
       "      <th>feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature 91</th>\n",
       "      <th>feature 92</th>\n",
       "      <th>feature 93</th>\n",
       "      <th>feature 94</th>\n",
       "      <th>feature 95</th>\n",
       "      <th>feature 96</th>\n",
       "      <th>feature 97</th>\n",
       "      <th>feature 98</th>\n",
       "      <th>feature 99</th>\n",
       "      <th>feature 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191681</td>\n",
       "      <td>0.681715</td>\n",
       "      <td>0.756724</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.822150</td>\n",
       "      <td>0.199785</td>\n",
       "      <td>0.738778</td>\n",
       "      <td>0.985086</td>\n",
       "      <td>0.374917</td>\n",
       "      <td>0.314246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518682</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.194376</td>\n",
       "      <td>0.540675</td>\n",
       "      <td>0.226328</td>\n",
       "      <td>0.304750</td>\n",
       "      <td>0.710070</td>\n",
       "      <td>0.837559</td>\n",
       "      <td>0.802265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.117275</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.966398</td>\n",
       "      <td>0.351835</td>\n",
       "      <td>0.304061</td>\n",
       "      <td>0.610628</td>\n",
       "      <td>0.488750</td>\n",
       "      <td>0.931685</td>\n",
       "      <td>0.806157</td>\n",
       "      <td>0.445136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147781</td>\n",
       "      <td>0.820527</td>\n",
       "      <td>0.816391</td>\n",
       "      <td>0.498862</td>\n",
       "      <td>0.137967</td>\n",
       "      <td>0.774840</td>\n",
       "      <td>0.815698</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.039020</td>\n",
       "      <td>0.056555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920883</td>\n",
       "      <td>0.937361</td>\n",
       "      <td>0.770071</td>\n",
       "      <td>0.423911</td>\n",
       "      <td>0.926546</td>\n",
       "      <td>0.850611</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>0.909356</td>\n",
       "      <td>0.902662</td>\n",
       "      <td>0.852342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859154</td>\n",
       "      <td>0.516553</td>\n",
       "      <td>0.752651</td>\n",
       "      <td>0.544660</td>\n",
       "      <td>0.360216</td>\n",
       "      <td>0.879797</td>\n",
       "      <td>0.880911</td>\n",
       "      <td>0.050922</td>\n",
       "      <td>0.789385</td>\n",
       "      <td>0.744718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588140</td>\n",
       "      <td>0.284251</td>\n",
       "      <td>0.674035</td>\n",
       "      <td>0.729705</td>\n",
       "      <td>0.268254</td>\n",
       "      <td>0.520289</td>\n",
       "      <td>0.415368</td>\n",
       "      <td>0.660507</td>\n",
       "      <td>0.668951</td>\n",
       "      <td>0.544255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900673</td>\n",
       "      <td>0.842319</td>\n",
       "      <td>0.188757</td>\n",
       "      <td>0.467804</td>\n",
       "      <td>0.280204</td>\n",
       "      <td>0.345736</td>\n",
       "      <td>0.725720</td>\n",
       "      <td>0.193215</td>\n",
       "      <td>0.458771</td>\n",
       "      <td>0.497181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.919214</td>\n",
       "      <td>0.209184</td>\n",
       "      <td>0.245116</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.820103</td>\n",
       "      <td>0.586720</td>\n",
       "      <td>0.665220</td>\n",
       "      <td>0.359731</td>\n",
       "      <td>0.206106</td>\n",
       "      <td>0.584706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143223</td>\n",
       "      <td>0.733424</td>\n",
       "      <td>0.447821</td>\n",
       "      <td>0.844970</td>\n",
       "      <td>0.645869</td>\n",
       "      <td>0.898718</td>\n",
       "      <td>0.752862</td>\n",
       "      <td>0.485091</td>\n",
       "      <td>0.980440</td>\n",
       "      <td>0.353727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.168559</td>\n",
       "      <td>0.201989</td>\n",
       "      <td>0.782727</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.835797</td>\n",
       "      <td>0.148582</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.894985</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.396547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744932</td>\n",
       "      <td>0.586659</td>\n",
       "      <td>0.401729</td>\n",
       "      <td>0.620584</td>\n",
       "      <td>0.316621</td>\n",
       "      <td>0.576131</td>\n",
       "      <td>0.463744</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0.287213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.772102</td>\n",
       "      <td>0.343814</td>\n",
       "      <td>0.975428</td>\n",
       "      <td>0.465960</td>\n",
       "      <td>0.808325</td>\n",
       "      <td>0.881415</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.244628</td>\n",
       "      <td>0.288478</td>\n",
       "      <td>0.766744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.835137</td>\n",
       "      <td>0.861921</td>\n",
       "      <td>0.561068</td>\n",
       "      <td>0.540907</td>\n",
       "      <td>0.807550</td>\n",
       "      <td>0.530856</td>\n",
       "      <td>0.851136</td>\n",
       "      <td>0.485639</td>\n",
       "      <td>0.644259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.810432</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>0.045015</td>\n",
       "      <td>0.029192</td>\n",
       "      <td>0.335937</td>\n",
       "      <td>0.506159</td>\n",
       "      <td>0.963874</td>\n",
       "      <td>0.407402</td>\n",
       "      <td>0.121867</td>\n",
       "      <td>0.052002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.818668</td>\n",
       "      <td>0.293306</td>\n",
       "      <td>0.853262</td>\n",
       "      <td>0.130221</td>\n",
       "      <td>0.600026</td>\n",
       "      <td>0.267106</td>\n",
       "      <td>0.515387</td>\n",
       "      <td>0.434660</td>\n",
       "      <td>0.688509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.349241</td>\n",
       "      <td>0.639312</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.940277</td>\n",
       "      <td>0.916994</td>\n",
       "      <td>0.798495</td>\n",
       "      <td>0.386195</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>0.742174</td>\n",
       "      <td>0.107218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540746</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.291170</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.521279</td>\n",
       "      <td>0.111949</td>\n",
       "      <td>0.346591</td>\n",
       "      <td>0.454785</td>\n",
       "      <td>0.377762</td>\n",
       "      <td>0.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.584790</td>\n",
       "      <td>0.405601</td>\n",
       "      <td>0.324868</td>\n",
       "      <td>0.412286</td>\n",
       "      <td>0.876679</td>\n",
       "      <td>0.748553</td>\n",
       "      <td>0.192974</td>\n",
       "      <td>0.173156</td>\n",
       "      <td>0.233651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684628</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.657875</td>\n",
       "      <td>0.183224</td>\n",
       "      <td>0.363146</td>\n",
       "      <td>0.375661</td>\n",
       "      <td>0.061053</td>\n",
       "      <td>0.268090</td>\n",
       "      <td>0.338965</td>\n",
       "      <td>0.501001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature 1  feature 2  feature 3  feature 4  feature 5  feature 6  \\\n",
       "0     0.191681   0.681715   0.756724   0.194280   0.822150   0.199785   \n",
       "1     0.117275   0.875857   0.966398   0.351835   0.304061   0.610628   \n",
       "2     0.920883   0.937361   0.770071   0.423911   0.926546   0.850611   \n",
       "3     0.588140   0.284251   0.674035   0.729705   0.268254   0.520289   \n",
       "4     0.919214   0.209184   0.245116   0.022100   0.820103   0.586720   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "195   0.168559   0.201989   0.782727   0.027003   0.835797   0.148582   \n",
       "196   0.772102   0.343814   0.975428   0.465960   0.808325   0.881415   \n",
       "197   0.810432   0.094476   0.045015   0.029192   0.335937   0.506159   \n",
       "198   0.349241   0.639312   0.609451   0.940277   0.916994   0.798495   \n",
       "199   0.035734   0.584790   0.405601   0.324868   0.412286   0.876679   \n",
       "\n",
       "     feature 7  feature 8  feature 9  feature 10  ...  feature 91  feature 92  \\\n",
       "0     0.738778   0.985086   0.374917    0.314246  ...    0.518682    0.086374   \n",
       "1     0.488750   0.931685   0.806157    0.445136  ...    0.147781    0.820527   \n",
       "2     0.839343   0.909356   0.902662    0.852342  ...    0.859154    0.516553   \n",
       "3     0.415368   0.660507   0.668951    0.544255  ...    0.900673    0.842319   \n",
       "4     0.665220   0.359731   0.206106    0.584706  ...    0.143223    0.733424   \n",
       "..         ...        ...        ...         ...  ...         ...         ...   \n",
       "195   0.009273   0.894985   0.608939    0.396547  ...    0.744932    0.586659   \n",
       "196   0.714263   0.244628   0.288478    0.766744  ...    0.005081    0.835137   \n",
       "197   0.963874   0.407402   0.121867    0.052002  ...    0.503330    0.818668   \n",
       "198   0.386195   0.207267   0.742174    0.107218  ...    0.540746    0.030817   \n",
       "199   0.748553   0.192974   0.173156    0.233651  ...    0.684628    0.973182   \n",
       "\n",
       "     feature 93  feature 94  feature 95  feature 96  feature 97  feature 98  \\\n",
       "0      0.963351    0.194376    0.540675    0.226328    0.304750    0.710070   \n",
       "1      0.816391    0.498862    0.137967    0.774840    0.815698    0.288172   \n",
       "2      0.752651    0.544660    0.360216    0.879797    0.880911    0.050922   \n",
       "3      0.188757    0.467804    0.280204    0.345736    0.725720    0.193215   \n",
       "4      0.447821    0.844970    0.645869    0.898718    0.752862    0.485091   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "195    0.401729    0.620584    0.316621    0.576131    0.463744    0.015369   \n",
       "196    0.861921    0.561068    0.540907    0.807550    0.530856    0.851136   \n",
       "197    0.293306    0.853262    0.130221    0.600026    0.267106    0.515387   \n",
       "198    0.291170    0.222700    0.521279    0.111949    0.346591    0.454785   \n",
       "199    0.657875    0.183224    0.363146    0.375661    0.061053    0.268090   \n",
       "\n",
       "     feature 99  feature 100  \n",
       "0      0.837559     0.802265  \n",
       "1      0.039020     0.056555  \n",
       "2      0.789385     0.744718  \n",
       "3      0.458771     0.497181  \n",
       "4      0.980440     0.353727  \n",
       "..          ...          ...  \n",
       "195    0.336376     0.287213  \n",
       "196    0.485639     0.644259  \n",
       "197    0.434660     0.688509  \n",
       "198    0.377762     0.006623  \n",
       "199    0.338965     0.501001  \n",
       "\n",
       "[200 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect features\n",
    "df_features_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect labels\n",
    "labels_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Of the features previously extracted, features highly correlated with another feature are identified and excluded from the analysis. This feature selection based on pair-wise feature correlation is applied to improve the machine learning training process and to enable optimized feature interpretability. For this purpose, we calculate a Pearson correlation matrix for all features extracted from the training set and exclude one feature of any feature pair with a Person correlation coefficient above 'corr_threshold'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove correlated features...\n",
      "Correlation threshold: 0.8\n",
      "Drop 0 / 100  features ( 0.0 %).\n",
      "Number of remaining features: 100\n"
     ]
    }
   ],
   "source": [
    "# Identify and remove strongly correlated features in the training dataset\n",
    "df_features_training_uncorr, dropped_features = remove_correlated_features(df_features_training, corr_threshold=corr_threshold)\n",
    "\n",
    "# Save names of features which have been dropped and will not be used for training or evaluating the random forest model\n",
    "dropped_features = np.asarray(dropped_features)\n",
    "np.savetxt('feature_selection/dropped_features.csv', dropped_features, newline=',', fmt='%s')\n",
    "\n",
    "# Save names of features which have been selected and will be used for training and evaluating the random forest model\n",
    "feature_names = df_features_training_uncorr.columns.to_numpy()\n",
    "np.savetxt('feature_selection/selected_features.csv', feature_names, newline=',', fmt='%s')\n",
    "print(\"Number of remaining features:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/trained_random_forest_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the training data, i.e. select the feature columns and the label column, respectively, and ignore the rest.\n",
    "X_train = df_features_training_uncorr.to_numpy()\n",
    "y_train = labels_training\n",
    "\n",
    "# Set up the random forest model\n",
    "rf = RandomForestClassifier(n_estimators=1000, oob_score=True, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "dump(rf, 'trained_models/trained_random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal validation (using out-of-bag predictions)\n",
    "\n",
    "We use the out-of-bag (OOB) predictions to get a point estimate of the performance that can be expected from the model for unseen data. In addition, we evaluate the out-of-bag predictions for a wide range of classification thresholds in order to pick and report three different models (A, B and C) later on (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a wide range of classification thresholds\n",
    "thresholds = np.linspace(0.0,1.0,n_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal evaluation\n",
    "oob_bin_acc     = []\n",
    "oob_sensitivity = []\n",
    "oob_specificity = []\n",
    "\n",
    "oob_roc_auc = roc_auc_score(y_train, rf.oob_decision_function_[:, 1])\n",
    "\n",
    "# Apply different thresholds for classification\n",
    "for t in thresholds:\n",
    "\n",
    "    # Adjust out-of-bag prediction for the current threshold\n",
    "    y_pred_adj = adjusted_prediction(rf.oob_decision_function_, threshold=t, positive_label=1)\n",
    "\n",
    "    # Out-of-bag prediction scores for the current threshold\n",
    "    bin_acc_thr = accuracy_score(y_train, y_pred_adj)\n",
    "    roc_auc_thr = roc_auc_score(y_train, rf.oob_decision_function_[:, 1])\n",
    "    sensitivity_thr, specificity_thr = eval_sensitivity_specificity(y_train, y_pred_adj)\n",
    "\n",
    "    oob_bin_acc.append(bin_acc_thr)\n",
    "    oob_sensitivity.append(sensitivity_thr)\n",
    "    oob_specificity.append(specificity_thr)\n",
    "\n",
    "oob_bin_acc     = np.asarray(oob_bin_acc)\n",
    "oob_sensitivity = np.asarray(oob_sensitivity)\n",
    "oob_specificity = np.asarray(oob_specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search classification thresholds\n",
    "\n",
    "Sensitivity, and specificity depend on the classification threshold, a parameter which is used to turn predicted class probabilities, i.e. the output of the random forest model (here: rf.oob_decision_function_) for a given input sample, into class predictions (benign versus premalignant).\n",
    "\n",
    "Here, we search for three different thresholds:\n",
    "1. A default threshold value of 0.5 (Model A)\n",
    "2. A threshold value which maximizes Youden's index (J=sensitivity+specificity1) (Model B)\n",
    "3. A threshold that results in the highest possible specificity while achieving a sensitivity of at least 0.85 (Model C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Youden's index J = 0.04 found for threshold T = 0.4850\n"
     ]
    }
   ],
   "source": [
    "# Find default threshold of 0.5\n",
    "ind_thr_50 = int(len(thresholds)/2.0)\n",
    "\n",
    "# Find threshold which maximizes Youden's index J\n",
    "J         = oob_sensitivity + oob_specificity - 1\n",
    "J_max     = np.amax(J)\n",
    "ind_J_max = np.argmax(J)\n",
    "print(\"Maximum Youden's index J = {:0.2f} found for threshold T = {:0.4f}\".format(J_max, thresholds[ind_J_max]))\n",
    "\n",
    "# Find threshold which yields sensitivity of 0.85\n",
    "ind_85 = 0\n",
    "while(oob_sensitivity[ind_85] >= 0.85):\n",
    "    ind_85 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal out-of-bag (OOB) validation:\n",
      "\n",
      "oob_roc_auc: 0.47\n",
      "\n",
      "OOB scores for threshold of 0.5 (Model A):\n",
      "\n",
      "bin_acc:     0.48\n",
      "sensitivity: 0.51\n",
      "specifity:   0.46\n",
      "\n",
      "OOB scores for a maximized Youden's Index (Model B, threshold = 0.485):\n",
      "\n",
      "bin_acc:     0.52\n",
      "sensitivity: 0.63\n",
      "specifity:   0.41\n",
      "\n",
      "OOB scores for a sensitivity of 0.85 (Model C, threshold = 0.443):\n",
      "\n",
      "bin_acc:     0.48\n",
      "sensitivity: 0.83\n",
      "specifity:   0.14\n"
     ]
    }
   ],
   "source": [
    "print(\"Internal out-of-bag (OOB) validation:\\n\")\n",
    "print('oob_roc_auc: {:.2f}'.format(oob_roc_auc))\n",
    "\n",
    "print(\"\\nOOB scores for threshold of {:0.1f} (Model A):\\n\".format(thresholds[ind_thr_50]))  \n",
    "print('bin_acc:     {:0.2f}'.format(oob_bin_acc[ind_thr_50]))\n",
    "print('sensitivity: {:0.2f}'.format(oob_sensitivity[ind_thr_50]))\n",
    "print('specifity:   {:0.2f}'.format(oob_specificity[ind_thr_50]))\n",
    "\n",
    "print(\"\\nOOB scores for a maximized Youden's Index (Model B, threshold = {:0.3f}):\\n\".format(thresholds[ind_J_max]))  \n",
    "print('bin_acc:     {:0.2f}'.format(oob_bin_acc[ind_J_max]))\n",
    "print('sensitivity: {:0.2f}'.format(oob_sensitivity[ind_J_max]))\n",
    "print('specifity:   {:0.2f}'.format(oob_specificity[ind_J_max]))\n",
    "\n",
    "print(\"\\nOOB scores for a sensitivity of 0.85 (Model C, threshold = {:0.3f}):\\n\".format(thresholds[ind_85]))  \n",
    "print('bin_acc:     {:0.2f}'.format(oob_bin_acc[ind_85]))\n",
    "print('sensitivity: {:0.2f}'.format(oob_sensitivity[ind_85]))\n",
    "print('specifity:   {:0.2f}'.format(oob_specificity[ind_85]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "The Scikit-learn random forest implementation provides an internal estimate of feature importance, i.e. how much the class prediction (benign versus premalignant) of a trained model depends on a specific feature relative to all other features. Here, we evaluate the relative importance of the 198 features used for training the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. feature  67: feature 68 (0.022222)\n",
      " 2. feature  12: feature 13 (0.017986)\n",
      " 3. feature  72: feature 73 (0.016780)\n",
      " 4. feature  19: feature 20 (0.015908)\n",
      " 5. feature  62: feature 63 (0.015708)\n",
      " 6. feature  59: feature 60 (0.015280)\n",
      " 7. feature   2: feature 3 (0.013607)\n",
      " 8. feature  11: feature 12 (0.013544)\n",
      " 9. feature  49: feature 50 (0.013539)\n",
      "10. feature  94: feature 95 (0.013394)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importance from random forest model\n",
    "importances, _ = extract_feature_importance(rf)\n",
    "\n",
    "# Rank features according to their importance\n",
    "ranked_features_id, ranked_features_name, ranked_importances = rank_feature_importance(importances, feature_names, n=10)\n",
    "\n",
    "# Plot feature importance\n",
    "plot_feature_importance(ranked_features_id, ranked_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
